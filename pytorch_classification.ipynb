{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96667267-00be-4d7d-b78e-90da3755a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuanzhang/miniconda3/envs/asl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytorch_lightning\n",
    "import pytorchvideo.data\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a46a0f-410e-46a8-9dba-cdca00234fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataModule(pytorch_lightning.LightningDataModule):\n",
    "\n",
    "  # Dataset configuration\n",
    "  _DATA_PATH = \"../WLASL/start_kit/videos/\"\n",
    "  _CLIP_DURATION = 2  # Duration of sampled clip for each video\n",
    "  _BATCH_SIZE = 8\n",
    "  _NUM_WORKERS = 8  # Number of parallel processes fetching data\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    \"\"\"\n",
    "    Create the ASL train partition from the list of video labels\n",
    "    in {self._DATA_PATH}/train\n",
    "    \"\"\"\n",
    "    train_dataset = pytorchvideo.data.Kinetics(\n",
    "        data_path=os.path.join(self._DATA_PATH, \"train\"),\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", self._CLIP_DURATION),\n",
    "        decode_audio=False,\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=self._BATCH_SIZE,\n",
    "        num_workers=self._NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    \"\"\"\n",
    "    Create the Kinetics validation partition from the list of video labels\n",
    "    in {self._DATA_PATH}/val\n",
    "    \"\"\"\n",
    "    val_dataset = pytorchvideo.data.Kinetics(\n",
    "        data_path=os.path.join(self._DATA_PATH, \"val\"),\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\", self._CLIP_DURATION),\n",
    "        decode_audio=False,\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=self._BATCH_SIZE,\n",
    "        num_workers=self._NUM_WORKERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d15d77-5a84-49b2-af0c-c985c32848c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3af473a-b96e-46c7-8d33-91e18e94339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pytorchvideo.data.kinetics.Kinetics(data_path: str, clip_sampler: pytorchvideo.data.clip_sampling.ClipSampler, video_sampler: Type[torch.utils.data.sampler.Sampler] = <class 'torch.utils.data.sampler.RandomSampler'>, transform: Union[Callable[[Dict[str, Any]], Dict[str, Any]], NoneType] = None, video_path_prefix: str = '', decode_audio: bool = True, decoder: str = 'pyav') -> pytorchvideo.data.labeled_video_dataset.LabeledVideoDataset>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorchvideo.data.Kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a950b25-aae4-4d68-b30d-6d345fd55ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(video_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8744eac1-8de0-434b-bb0d-2c4461d3aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- -----------\n",
      "anyio                         3.6.2\n",
      "appnope                       0.1.3\n",
      "argon2-cffi                   21.1.0\n",
      "asttokens                     2.2.1\n",
      "attrs                         22.2.0\n",
      "Babel                         2.12.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.12.2\n",
      "bleach                        6.0.0\n",
      "brotlipy                      0.7.0\n",
      "certifi                       2022.12.7\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            3.1.0\n",
      "colorama                      0.4.6\n",
      "cryptography                  39.0.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "entrypoints                   0.4\n",
      "executing                     1.2.0\n",
      "fastjsonschema                2.16.3\n",
      "fsspec                        2023.4.0\n",
      "future                        0.18.3\n",
      "idna                          3.4\n",
      "importlib-metadata            6.6.0\n",
      "importlib-resources           5.12.0\n",
      "ipykernel                     5.5.5\n",
      "ipython                       8.12.0\n",
      "ipython-genutils              0.2.0\n",
      "jedi                          0.18.2\n",
      "Jinja2                        3.1.2\n",
      "json5                         0.9.5\n",
      "jsonschema                    4.17.3\n",
      "jupyter-client                7.3.4\n",
      "jupyter_core                  5.3.0\n",
      "jupyter-server                1.23.6\n",
      "jupyterlab                    3.5.3\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab_server             2.22.1\n",
      "lightning-utilities           0.8.0\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib-inline             0.1.6\n",
      "mistune                       2.0.5\n",
      "nbclassic                     0.5.6\n",
      "nbclient                      0.7.4\n",
      "nbconvert                     7.3.1\n",
      "nbformat                      5.8.0\n",
      "nest-asyncio                  1.5.6\n",
      "notebook                      6.5.4\n",
      "notebook_shim                 0.2.3\n",
      "numpy                         1.24.3\n",
      "packaging                     23.1\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.0.1\n",
      "pkgutil_resolve_name          1.3.10\n",
      "platformdirs                  3.5.0\n",
      "prometheus-client             0.16.0\n",
      "prompt-toolkit                3.0.38\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pycparser                     2.21\n",
      "Pygments                      2.15.1\n",
      "pyOpenSSL                     23.1.1\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.2\n",
      "pytorch-lightning             2.0.2\n",
      "pytz                          2023.3\n",
      "PyYAML                        6.0\n",
      "pyzmq                         25.0.2\n",
      "requests                      2.29.0\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    66.0.0\n",
      "six                           1.16.0\n",
      "sniffio                       1.3.0\n",
      "soupsieve                     2.3.2.post1\n",
      "stack-data                    0.6.2\n",
      "terminado                     0.17.1\n",
      "tinycss2                      1.2.1\n",
      "tomli                         2.0.1\n",
      "torch                         1.12.1\n",
      "torchaudio                    0.12.1\n",
      "torchmetrics                  0.11.4\n",
      "torchvision                   0.13.1\n",
      "tornado                       6.1\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.9.0\n",
      "typing_extensions             4.5.0\n",
      "urllib3                       1.26.15\n",
      "wcwidth                       0.2.6\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.5.1\n",
      "wheel                         0.38.4\n",
      "zipp                          3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35654ba8-f212-4daa-9079-750ffe6e5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_dir, split=\"train\", test_size=0.1, val_size=0.1, random_state=429):\n",
    "        self.labels = os.listdir(data_dir)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels)}\n",
    "        self.data = []\n",
    "        for label in self.labels:\n",
    "            label_dir = os.path.join(data_dir, label)\n",
    "            video_files = os.listdir(label_dir)\n",
    "            video_paths = [os.path.join(label_dir, video_file) for video_file in video_files]\n",
    "\n",
    "            train_val_paths, test_paths = train_test_split(video_paths, test_size=test_size, random_state=random_state)\n",
    "            train_paths, val_paths = train_test_split(train_val_paths, test_size=val_size/(1-test_size), random_state=random_state)\n",
    "\n",
    "            if split == \"train\":\n",
    "                self.data += [(video_path, label) for video_path in train_paths]\n",
    "            elif split == \"val\":\n",
    "                self.data += [(video_path, label) for video_path in val_paths]\n",
    "            elif split == \"test\":\n",
    "                self.data += [(video_path, label) for video_path in test_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.data[idx]\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = transforms.ToTensor()(frame)\n",
    "            frames.append(frame)\n",
    "        video_tensor = torch.stack(frames, dim=0)\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        return video_tensor, label_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d9edbe1-240e-407e-8ce4-84d6efe375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VideoDataset(video_dir, split=\"train\")\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "\n",
    "val_data = VideoDataset(video_dir, split=\"val\")\n",
    "val_loader = DataLoader(val_data, batch_size=4, shuffle=True)\n",
    "\n",
    "test_data = VideoDataset(video_dir, split=\"test\")\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd7383a3-7eb0-453c-9c02-46ba565ffc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x13d8d0550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
